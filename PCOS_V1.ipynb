{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Essential Libraries for PCOS Feature Harmonization\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np   # For numerical operations and handling missing values\n",
        "from sklearn.preprocessing import StandardScaler  # For standardizing features (if needed in your pipeline)\n",
        "\n",
        "# Optional but useful libraries for visualization and additional processing\n",
        "import matplotlib.pyplot as plt  # For creating visualizations\n",
        "import seaborn as sns            # For enhanced visualizations\n",
        "from scipy import stats          # For statistical operations (if needed)"
      ],
      "metadata": {
        "id": "dZJbNtQ8axUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPxuG-sIai3R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class PCOSFeatureHarmonizer:\n",
        "    \"\"\"\n",
        "    A class to harmonize PCOS datasets from different geographic regions\n",
        "    by standardizing features, units, and handling missing values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define the 18 common features across all cohorts\n",
        "        self.common_features = [\n",
        "            'Follicle No. (R)', 'Follicle No. (L)', 'Skin darkening (Y/N)',\n",
        "            'Hair growth (Y/N)', 'Weight gain (Y/N)', 'Cycle (R/I)',\n",
        "            'Pimples (Y/N)', 'AMH (ng/mL)', 'Weight (Kg)', 'Cycle length (days)',\n",
        "            'Age (yrs)', 'Hip (inch)', 'BMI', 'Avg. F size (L) (mm)',\n",
        "            'Pulse rate (bpm)', 'Hb (g/dl)', 'Vit D3 (ng/mL)', 'FSH/LH ratio'\n",
        "        ]\n",
        "\n",
        "        # Define unit conversion factors\n",
        "        self.conversion_factors = {\n",
        "            'Testosterone': 28.84,  # nmol/L to ng/dL\n",
        "            'Waist': 2.54,  # cm to inches\n",
        "            'Hip': 2.54,    # cm to inches\n",
        "        }\n",
        "\n",
        "    def load_dataset(self, file_path, dataset_name):\n",
        "        \"\"\"\n",
        "        Load a dataset from the given file path\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Loaded {dataset_name} dataset with shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def rename_features(self, df, mapping_dict):\n",
        "        \"\"\"\n",
        "        Rename features according to a mapping dictionary\n",
        "        \"\"\"\n",
        "        return df.rename(columns=mapping_dict)\n",
        "\n",
        "    def convert_units(self, df, cohort_name):\n",
        "        \"\"\"\n",
        "        Convert units to standard format across all cohorts\n",
        "        \"\"\"\n",
        "        df_converted = df.copy()\n",
        "\n",
        "        # Kerala dataset typically already uses standard units\n",
        "        if cohort_name != \"Kerala\":\n",
        "            # Convert testosterone if present\n",
        "            if 'Testosterone (nmol/L)' in df_converted.columns:\n",
        "                df_converted['Testosterone (ng/dL)'] = df_converted['Testosterone (nmol/L)'] * self.conversion_factors['Testosterone']\n",
        "                df_converted.drop('Testosterone (nmol/L)', axis=1, inplace=True)\n",
        "\n",
        "            # Convert waist and hip measurements from cm to inches if needed\n",
        "            if 'Waist (cm)' in df_converted.columns:\n",
        "                df_converted['Waist (inch)'] = df_converted['Waist (cm)'] / self.conversion_factors['Waist']\n",
        "                df_converted.drop('Waist (cm)', axis=1, inplace=True)\n",
        "\n",
        "            if 'Hip (cm)' in df_converted.columns:\n",
        "                df_converted['Hip (inch)'] = df_converted['Hip (cm)'] / self.conversion_factors['Hip']\n",
        "                df_converted.drop('Hip (cm)', axis=1, inplace=True)\n",
        "\n",
        "        return df_converted\n",
        "\n",
        "    def encode_categorical_variables(self, df):\n",
        "        \"\"\"\n",
        "        Encode categorical variables consistently across datasets\n",
        "        \"\"\"\n",
        "        df_encoded = df.copy()\n",
        "\n",
        "        # Binary features mapping\n",
        "        binary_mappings = {\n",
        "            'Skin darkening (Y/N)': {'Yes': 1, 'No': 0, 'Present': 1, 'Absent': 0},\n",
        "            'Hair growth (Y/N)': {'Yes': 1, 'No': 0, 'Present': 1, 'Absent': 0},\n",
        "            'Weight gain (Y/N)': {'Yes': 1, 'No': 0, 'Present': 1, 'Absent': 0},\n",
        "            'Pimples (Y/N)': {'Yes': 1, 'No': 0, 'Present': 1, 'Absent': 0},\n",
        "            'Cycle (R/I)': {'Regular': 0, 'Irregular': 1, 'R': 0, 'I': 1}\n",
        "        }\n",
        "\n",
        "        for feature, mapping in binary_mappings.items():\n",
        "            if feature in df_encoded.columns:\n",
        "                df_encoded[feature] = df_encoded[feature].map(mapping)\n",
        "\n",
        "        return df_encoded\n",
        "\n",
        "    def handle_missing_values(self, df, reference_df=None):\n",
        "        \"\"\"\n",
        "        Handle missing values using mean/mode imputation\n",
        "        If reference_df is provided, use its statistics for imputation\n",
        "        \"\"\"\n",
        "        df_imputed = df.copy()\n",
        "\n",
        "        # Use reference dataset statistics if provided\n",
        "        if reference_df is not None:\n",
        "            for column in df_imputed.columns:\n",
        "                if df_imputed[column].isnull().any():\n",
        "                    if df_imputed[column].dtype in ['int64', 'float64']:\n",
        "                        # Continuous variable - use mean from reference\n",
        "                        impute_value = reference_df[column].mean()\n",
        "                    else:\n",
        "                        # Categorical variable - use mode from reference\n",
        "                        impute_value = reference_df[column].mode()[0]\n",
        "\n",
        "                    df_imputed[column].fillna(impute_value, inplace=True)\n",
        "        else:\n",
        "            # Impute with current dataset's statistics\n",
        "            for column in df_imputed.columns:\n",
        "                if df_imputed[column].isnull().any():\n",
        "                    if df_imputed[column].dtype in ['int64', 'float64']:\n",
        "                        df_imputed[column].fillna(df_imputed[column].mean(), inplace=True)\n",
        "                    else:\n",
        "                        df_imputed[column].fillna(df_imputed[column].mode()[0], inplace=True)\n",
        "\n",
        "        return df_imputed\n",
        "\n",
        "    def harmonize_datasets(self, kerala_df, sudan_df, iran_df):\n",
        "        \"\"\"\n",
        "        Main method to harmonize all three datasets\n",
        "        \"\"\"\n",
        "        print(\"Starting dataset harmonization...\")\n",
        "\n",
        "        # Use Kerala as reference for imputation\n",
        "        reference_df = kerala_df[self.common_features].copy()\n",
        "\n",
        "        # Process each dataset\n",
        "        processed_datasets = {}\n",
        "\n",
        "        # Kerala dataset\n",
        "        kerala_processed = reference_df.copy()\n",
        "        kerala_processed = self.encode_categorical_variables(kerala_processed)\n",
        "        kerala_processed = self.handle_missing_values(kerala_processed)\n",
        "        processed_datasets['Kerala'] = kerala_processed\n",
        "\n",
        "        # Sudan dataset\n",
        "        sudan_processed = sudan_df[self.common_features].copy()\n",
        "        sudan_processed = self.convert_units(sudan_processed, \"Sudan\")\n",
        "        sudan_processed = self.encode_categorical_variables(sudan_processed)\n",
        "        sudan_processed = self.handle_missing_values(sudan_processed, reference_df)\n",
        "        processed_datasets['Sudan'] = sudan_processed\n",
        "\n",
        "        # Iran dataset\n",
        "        iran_processed = iran_df[self.common_features].copy()\n",
        "        iran_processed = self.convert_units(iran_processed, \"Iran\")\n",
        "        iran_processed = self.encode_categorical_variables(iran_processed)\n",
        "        iran_processed = self.handle_missing_values(iran_processed, reference_df)\n",
        "        processed_datasets['Iran'] = iran_processed\n",
        "\n",
        "        print(\"Dataset harmonization completed successfully!\")\n",
        "        return processed_datasets\n",
        "\n",
        "    def generate_summary_report(self, processed_datasets):\n",
        "        \"\"\"\n",
        "        Generate a summary report of the harmonized datasets\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"HARMONIZATION SUMMARY REPORT\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        for cohort, df in processed_datasets.items():\n",
        "            print(f\"\\n{cohort} Dataset:\")\n",
        "            print(f\"  Samples: {len(df)}\")\n",
        "            print(f\"  Features: {len(df.columns)}\")\n",
        "            print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "            # Count PCOS cases if target variable exists\n",
        "            if 'PCOS (Y/N)' in df.columns:\n",
        "                pcos_cases = df['PCOS (Y/N)'].sum()\n",
        "                print(f\"  PCOS cases: {ppos_cases} ({pcos_cases/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Example of how to use the PCOSFeatureHarmonizer class\n",
        "    \"\"\"\n",
        "    # Initialize the harmonizer\n",
        "    harmonizer = PCOSFeatureHarmonizer()\n",
        "\n",
        "    # Load datasets (replace with actual file paths)\n",
        "    # Note: These paths should point to your actual dataset files\n",
        "    kerala_df = harmonizer.load_dataset(\"/content/kerala_pcos.csv\", \"Kerala\")\n",
        "    sudan_df = harmonizer.load_dataset(\"/content/sudan_pcos.csv\", \"Sudan\")\n",
        "    iran_df = harmonizer.load_dataset(\"/content/iran_pcos.csv\", \"Iran\")\n",
        "\n",
        "    # Define feature mapping for each dataset if needed\n",
        "    # This is necessary if feature names differ across datasets\n",
        "    sudan_mapping = {\n",
        "        'right_follicle_count': 'Follicle No. (R)',\n",
        "        'left_follicle_count': 'Follicle No. (L)',\n",
        "        # Add more mappings as needed\n",
        "    }\n",
        "\n",
        "    iran_mapping = {\n",
        "        'Follicle_R': 'Follicle No. (R)',\n",
        "        'Follicle_L': 'Follicle No. (L)',\n",
        "        # Add more mappings as needed\n",
        "    }\n",
        "\n",
        "    # Apply feature mapping if necessary\n",
        "    sudan_df = harmonizer.rename_features(sudan_df, sudan_mapping)\n",
        "    iran_df = harmonizer.rename_features(iran_df, iran_mapping)\n",
        "\n",
        "    # Harmonize datasets\n",
        "    processed_datasets = harmonizer.harmonize_datasets(kerala_df, sudan_df, iran_df)\n",
        "\n",
        "    # Generate summary report\n",
        "    harmonizer.generate_summary_report(processed_datasets)\n",
        "\n",
        "    # Save harmonized datasets\n",
        "    for cohort, df in processed_datasets.items():\n",
        "        df.to_csv(f\"/content/{cohort.lower()}_harmonized.csv\", index=False)\n",
        "        print(f\"Saved harmonized {cohort} dataset to {cohort.lower()}_harmonized.csv\")\n",
        "\n",
        "    print(\"\\nHarmonization process completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}